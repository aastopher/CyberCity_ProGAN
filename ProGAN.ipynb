{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e46928c",
   "metadata": {},
   "source": [
    "### SKELETON - THIS NOTEBOOK IS INTENDED TO BE GUTTED FOR A NEW PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c57c369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T12:49:22.399755Z",
     "iopub.status.busy": "2022-01-09T12:49:22.398100Z",
     "iopub.status.idle": "2022-01-09T12:49:24.148062Z",
     "shell.execute_reply": "2022-01-09T12:49:24.148670Z",
     "shell.execute_reply.started": "2022-01-09T12:39:54.477925Z"
    },
    "papermill": {
     "duration": 1.76593,
     "end_time": "2022-01-09T12:49:24.148987",
     "exception": false,
     "start_time": "2022-01-09T12:49:22.383057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x203ad4de9f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import io\n",
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import argparse\n",
    "\n",
    "# define seed\n",
    "manualSeed = 999\n",
    "print(f\"Seed: {manualSeed}\")\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0073270c",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e14b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training imgs download url + output file name definition\n",
    "url = 'https://drive.google.com/uc?id=1A423Vi62SWb3FHtwieXDlmtIEcQHb2ub'\n",
    "outfile = \"imgs.zip\"\n",
    "\n",
    "# download imgs if imgs folder does not exist\n",
    "if not os.path.exists(\"imgs\"):\n",
    "    gdown.download(url, outfile, quiet=False)\n",
    "\n",
    "    with zipfile.ZipFile(outfile, 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "    os.remove(\"imgs.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b047c9",
   "metadata": {},
   "source": [
    "### Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3e7d2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd() # collect current working directory\n",
    "dataroot = Path(f\"{cwd}/imgs\") # define data directory\n",
    "workers = 2 # number of workers for dataloader\n",
    "batch_size = 128 # batch size during training (64 + 64)\n",
    "num_channels = 3 # number of channels in the training images. For color images this is 3 (RGB)\n",
    "image_size = 64 # also the size of feature maps for the generator and discriminator\n",
    "z_size = 100 # size of z latent vector (i.e. size of generator input)\n",
    "num_epochs = 100 # number of training epochs\n",
    "# num_epochs = 400 # number of training epochs\n",
    "lr = 0.0002 # learning rate for optimizers\n",
    "num_gpu = 2 # number of GPUs available. Use 0 for CPU mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6666cf6d",
   "metadata": {},
   "source": [
    "### Define Transforms, Loaders, and preview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc3a59c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T12:49:24.208255Z",
     "iopub.status.busy": "2022-01-09T12:49:24.207705Z",
     "iopub.status.idle": "2022-01-09T12:49:39.109933Z",
     "shell.execute_reply": "2022-01-09T12:49:39.110341Z",
     "shell.execute_reply.started": "2022-01-09T12:41:08.029699Z"
    },
    "papermill": {
     "duration": 14.920331,
     "end_time": "2022-01-09T12:49:39.110485",
     "exception": false,
     "start_time": "2022-01-09T12:49:24.190154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define transform\n",
    "tfs = transforms.Compose([transforms.Resize(image_size),\n",
    "                          transforms.CenterCrop(image_size),\n",
    "                          transforms.ToTensor(),\n",
    "                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),]) # range per channel = [-1,1]\n",
    "\n",
    "# define the dataset\n",
    "dataset = dset.ImageFolder(root=dataroot,transform=tfs)\n",
    "\n",
    "# define the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)\n",
    "\n",
    "# define available device\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and num_gpu > 0) else \"cpu\")\n",
    "\n",
    "# plot training image grid\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py309': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1019.594785,
   "end_time": "2022-01-09T13:06:13.199330",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-09T12:49:13.604545",
   "version": "2.3.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "0bc65f2bf3d2a0f29751611fa3005bd3fd265ee8bd01417e9d929835e1c4378f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
